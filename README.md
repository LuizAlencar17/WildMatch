# WildMatch: Weakly-Supervised Visual Species Identification

This repository contains a simplified research-oriented pipeline for species identification from images using vision-language models (VLMs) together with an LLM-augmented taxonomy-driven knowledge base (KB).  
The core objective is to evaluate whether multiple caption samples generated by a visual model, combined with language-based reasoning over a curated KB, can produce reliable species predictions.

---


## üîç Pipeline Overview

The workflow is composed of three main computational stages:

1. **Knowledge Base Construction (`kb_builder.py`)**
   - Fetches Wikipedia summaries for target species
   - Applies an LLM-based filtering and rewriting process focused solely on *visible phenotype*
   - Stores the curated descriptions into `data/knowledge_base.json`

2. **Caption Sampling via VLM (`vlm_captioner.py`)**
   - Uses `nlpconnect/vit-gpt2-image-captioning`
   - Produces multiple caption hypotheses from a single image
   - Helps reduce hallucinations and uncertainty by sampling variability

3. **LLM-Based Species Matching (`wildmatch.py`)**
   - Each caption is compared against the KB in a *single-step zero-shot reasoning call*
   - Results are aggregated via majority voting
   - Final output includes prediction, confidence score, and vote distribution

---

## üöÄ Quick Start

### 1Ô∏è‚É£ Install dependencies
```bash
pip install torch transformers pillow requests openai
```

### 2Ô∏è‚É£ Set your OpenAI API key

```bash
export OPENAI_API_KEY="YOUR_KEY_HERE"
```

### 3Ô∏è‚É£ Build or update the knowledge base (optional)

```bash
python kb_builder.py
```

### 4Ô∏è‚É£ Run prediction on an image

```bash
python wildmatch.py
```

Default input path inside `wildmatch.py`:

```python
result = wildmatch_predict("images/zebra.jpeg")
```

---

## üì¶ Example Output Format

```json
{
  "prediction": "Panthera onca",
  "confidence": 0.8,
  "caption_samples": [
    "a spotted wild cat standing in tall grass",
    "a jaguar-like animal in the jungle",
    "..."
  ],
  "species_votes": ["Panthera onca", "Panthera onca", "Puma concolor", ...],
  "vote_counts": {
    "Panthera onca": 4,
    "Puma concolor": 1
  }
}
```

---

## üß© Extensibility

This framework can be adapted for:

* Multi-modal ecological datasets
* Field camera trap monitoring
* Zero-shot wildlife classification benchmarks
* New species integration via automated KB building
* Confidence-aware ensemble decision systems

Future planned extensions may include:

* Taxonomy graph reasoning
* Few-shot image embeddings
* Multi-LLM evaluation and ensembling
* Species uncertainty thresholds and abstention logic

---

## ‚ö†Ô∏è Notes

* This implementation is intended for research and prototyping purposes, not production-level classification.
* Visual caption models may hallucinate attributes; majority sampling mitigates but does not eliminate this.
* The KB depends on public Wikipedia summaries and the correctness of LLM transformations.

---

## üìú License

This repository is shared for academic and experimental use.
Adapt, modify, and expand based on your research needs.

---

## ü§ù Contributions

PRs, discussion, and scientific benchmarking are welcome.
Feel free to open issues suggesting feature extensions and evaluation datasets.

```

If you'd like, I can also prepare:
- badges and shields
- results tables
- visual architecture diagrams
- instructions for dataset expansion
- experiment logs & reproducible configs
```
